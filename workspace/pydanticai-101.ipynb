{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Build Your First AI Agent with PydanticAI: Customer Chat Support**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PydanticAI is an innovative, Python-based framework developed by the creators of Pydantic, designed to build reliable, structured, and type-safe AI agents powered by Large Language Models (LLMs). Unlike traditional prompt-centric AI development, PydanticAI introduces a schema-first, developer-centric approach that ensures LLM responses are predictable, validated, and aligned with strongly typed Python models.\n",
    "\n",
    "At the heart of PydanticAI is the idea of treating AI agents as strongly typed functions. Developers define the inputs and outputs of their agents using standard Pydantic models, and the framework ensures that all AI responses conform to these constraints. This tight integration between LLM reasoning and Python typing empowers developers to build robust agents without the uncertainty and fragility commonly associated with free-form LLM outputs.\n",
    " \n",
    "Here in this guided project, we are building a customer support chatbot using PydanticAI, trained on Kaggle's customer support ticket dataset. The chatbot uses structured schemas to classify user queries into categories, assign priority levels, escalate where necessary, and generate consistent, professional responses.\n",
    "\n",
    "It‚Äôs a practical, real-world application that highlights how to turn raw AI potential into operational excellence‚Äîall using type-safe models and modular agent design.\n",
    "\n",
    "Whether you‚Äôre building support bots, legal agents, data annotators, or AI workflow chains, PydanticAI empowers you to build with confidence, clarity, and control‚Äîwithout compromising on the power of LLMs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Table of Contents__\n",
    "\n",
    "<ol>\n",
    "    <li><a href=\"#Objectives\">Objectives</a></li>\n",
    "    <li>\n",
    "        <a href=\"#Setup\">Setup</a>\n",
    "        <ol>\n",
    "            <li><a href=\"#Installing-Required-Libraries\">Installing Required Libraries</a></li>\n",
    "            <li><a href=\"#Importing-Required-Libraries\">Importing Required Libraries</a></li>\n",
    "            <li><a href=\"#Defining-Helper-Functions\">Defining Helper Functions</a></li>\n",
    "        </ol>\n",
    "    </li>\n",
    "    <li>\n",
    "        <a href=\"#What-is-PydanticAI?\">What is PydanticAI?</a>\n",
    "         <li><a href=\"#Why-was-PydanticAI-created?\"> Why was PydanticAI created?</a></li>\n",
    "        <li><a href=\"#Key-Features-of-PydanticAI:\">Key Features of PydanticAI:</a></li>\n",
    "         <li><a href=\"#About-Dataset\">About Dataset</a></li>\n",
    "    <li><a href=\"#Load-Dataset\">Load Dataset</a></li>\n",
    "    </li>\n",
    "    <li><a href=\"#What-is-an-Agent?\">What is an Agent?</a></li>\n",
    "    <li><a href=\"#What-is-nest_asyncio?\">What is nest_asyncio?</a></li>\n",
    "</ol>\n",
    "\n",
    "<a href=\"#Exercises\">Exercises</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "- Understand the core concepts of AI agentic systems and their applications.\n",
    "- Learn how to use Pydantic for data modeling, validation, and serialization within agent frameworks.\n",
    "- Define and implement modular, structured AI agents using the Pydantic Agentic Framework.\n",
    "- Orchestrate multi-step reasoning and decision-making processes in agents.\n",
    "- Integrate external tools and APIs to enhance agent capabilities.\n",
    "- Design agents that are scalable, interpretable, and maintainable for real-world use cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "*   [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for managing the data.\n",
    "*   [`numpy`](https://numpy.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for mathematical operations.\n",
    "*   [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for machine learning and machine-learning-pipeline related functions.\n",
    "*   [`seaborn`](https://seaborn.pydata.org/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork31430127-2021-01-01) for visualizing the data.\n",
    "*   [`pydentic-ai`](https://ai.pydantic.dev/) is a Python agent framework designed to build production grade applications with Generative AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed anthropic-0.72.0 argcomplete-3.6.3 boto3-1.40.67 botocore-1.40.67 cachetools-6.2.1 click-8.3.0 cohere-5.20.0 docstring-parser-0.17.0 eval-type-backport-0.2.2 fastavro-1.12.1 filelock-3.20.0 fsspec-2025.10.0 google-auth-2.43.0 griffe-1.14.0 groq-0.33.0 hf-xet-1.2.0 httpx-sse-0.4.0 huggingface-hub-1.1.1 invoke-2.2.1 jiter-0.11.1 jmespath-1.0.1 logfire-api-4.14.2 markdown-it-py-4.0.0 mcp-1.20.0 mdurl-0.1.2 mistralai-1.9.11 numpy-2.3.4 openai-2.7.1 opentelemetry-api-1.38.0 pandas-2.2.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.12.4 pydantic-ai-0.1.3 pydantic-ai-slim-0.1.3 pydantic-core-2.41.5 pydantic-evals-0.1.3 pydantic-graph-0.1.3 pydantic-settings-2.11.0 python-dotenv-1.2.1 python-multipart-0.0.20 rich-14.2.0 rsa-4.9.1 s3transfer-0.14.0 shellingham-1.5.4 sse-starlette-3.0.3 starlette-0.50.0 tokenizers-0.22.1 typer-slim-0.20.0 types-requests-2.32.4.20250913 typing-extensions-4.15.0 typing-inspection-0.4.2 tzdata-2025.2 uvicorn-0.38.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic-ai==0.1.3 pandas==2.2.3 | tail -n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/nQn6NwuUQcQ7E90e29UJbw/Restarting-the-Kernel.png\" width=\"70%\" alt=\"Restart kernel\">\n",
    "\n",
    "**Note:** After completing the library installation, the next step is to restart the kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.12.8 | packaged by conda-forge | (main, Dec  5 2024, 14:24:40) [GCC 13.3.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, validator, Field, field_validator\n",
    "from openai import OpenAI\n",
    "from pydantic_ai import Agent, RunContext\n",
    "import nest_asyncio\n",
    "from dataclasses import dataclass  \n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PydanticAI?\n",
    "PydanticAI is a powerful open-source Python framework built to simplify the process of developing production-ready applications using Generative AI (GenAI), such as Large Language Models (LLMs). \n",
    "\n",
    "It‚Äôs designed for developers who want to create smart AI agents and applications that are structured, maintainable, and scalable.\n",
    "\n",
    "# Why was PydanticAI created?\n",
    "In the world of Python, Pydantic is widely used for data validation and settings management, and FastAPI made web development faster and cleaner by building on top of Pydantic.\n",
    "\n",
    "When the team behind Pydantic started using LLMs in their own tool called Logfire, they noticed a gap ‚Äî there wasn‚Äôt any agent framework that provided the same smooth experience that FastAPI offered for APIs. Most existing LLM tools were either too complex, too loosely structured, or hard to manage at scale.\n",
    "\n",
    "So they built PydanticAI with one goal:\n",
    "\n",
    "‚ÄúBring the developer-friendly experience of FastAPI to the world of GenAI apps.‚Äù\n",
    "\n",
    "# Key Features of PydanticAI:\n",
    "1. Agent-Oriented Design: Agents are central to PydanticAI, acting as containers that manage prompts, tools, and structured outputs, facilitating complex workflows and multi-agent interactions.\n",
    "\n",
    "2. Type Safety and Validation: Leveraging Pydantic's robust type system, it ensures data integrity and clarity in agent behaviors, reducing runtime errors.‚Äã\n",
    "\n",
    "3. Model-Agnostic Compatibility: Supports various LLMs, including OpenAI, Anthropic, Gemini, Deepseek, Ollama, Groq, Cohere, and Mistral, with a straightforward interface for integrating additional models.\n",
    "\n",
    "4. Integration with Pydantic Logfire: Offers seamless debugging, performance monitoring, and behavior tracking, enhancing the observability of LLM-powered applications.\n",
    "\n",
    "5. Python-Centric Approach: Emphasizes familiar Python control flows and best practices, making it accessible for developers to build and maintain AI-driven projects.\n",
    "\n",
    "You can learn more about PydanticAI - https://ai.pydantic.dev/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About Dataset\n",
    "In this lab we will use the kagglehub library (which is an unofficial utility that simplifies accessing Kaggle datasets programmatically), also downloads the latest version of the Kaggle dataset titled \"customer-support-ticket-dataset\" owned by the user suraj520 from here - https://www.kaggle.com/datasets/suraj520/customer-support-ticket-dataset\n",
    "\n",
    "The Customer Support Ticket Dataset is a dataset that includes customer support tickets for various tech products. It consists of customer inquiries related to hardware issues, software bugs, network problems, account access, data loss, and other support topics. The dataset provides information about the customer, the product purchased, the ticket type, the ticket channel, the ticket status, and other relevant details.\n",
    "\n",
    "The dataset can be used for various analysis and modelling tasks in the customer service domain.\n",
    "\n",
    "Features Description:\n",
    "Ticket ID: A unique identifier for each ticket.  \n",
    "Customer Name: The name of the customer who raised the ticket.  \n",
    "Customer Email: The email address of the customer (Domain name - @example.com is intentional for user data privacy concern).  \n",
    "Customer Age: The age of the customer.  \n",
    "Customer Gender: The gender of the customer.  \n",
    "Product Purchased: The tech product purchased by the customer.  \n",
    "Date of Purchase: The date when the product was purchased.  \n",
    "Ticket Type: The type of ticket (e.g., technical issue, billing inquiry, product inquiry).  \n",
    "Ticket Subject: The subject/topic of the ticket.  \n",
    "Ticket Description: The description of the customer's issue or inquiry.  \n",
    "Ticket Status: The status of the ticket (e.g., open, closed, pending customer response).  \n",
    "Resolution: The resolution or solution provided for closed tickets.  \n",
    "Ticket Priority: The priority level assigned to the ticket (e.g., low, medium, high, critical).  \n",
    "Ticket Channel: The channel through which the ticket was raised (e.g., email, phone, chat, social media).  \n",
    "First Response Time: The time taken to provide the first response to the customer.  \n",
    "Time to Resolution: The time taken to resolve the ticket.  \n",
    "Customer Satisfaction Rating: The customer's satisfaction rating for closed tickets (on a scale of 1 to 5).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "The function dataset_download() handles:\n",
    "- Authentication with Kaggle (if set up properly),\n",
    "- Checking if the dataset is already downloaded (uses caching),\n",
    "- Downloading and extracting it if not present.\n",
    "\n",
    "It returns the path to the folder where the dataset has been saved locally and assigns it to the variable path.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.read_csv() is a function that reads the CSV file and loads it into a DataFrame, which is a tabular data structure (like a table in Excel or a database).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IJIikY8I-Q79KdIA5WtYIw/customer-support-tickets.csv\"\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticket ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Customer Email</th>\n",
       "      <th>Customer Age</th>\n",
       "      <th>Customer Gender</th>\n",
       "      <th>Product Purchased</th>\n",
       "      <th>Date of Purchase</th>\n",
       "      <th>Ticket Type</th>\n",
       "      <th>Ticket Subject</th>\n",
       "      <th>Ticket Description</th>\n",
       "      <th>Ticket Status</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Ticket Priority</th>\n",
       "      <th>Ticket Channel</th>\n",
       "      <th>First Response Time</th>\n",
       "      <th>Time to Resolution</th>\n",
       "      <th>Customer Satisfaction Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marisa Obrien</td>\n",
       "      <td>carrollallison@example.com</td>\n",
       "      <td>32</td>\n",
       "      <td>Other</td>\n",
       "      <td>GoPro Hero</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Product setup</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 12:15:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jessica Rios</td>\n",
       "      <td>clarkeashley@example.com</td>\n",
       "      <td>42</td>\n",
       "      <td>Female</td>\n",
       "      <td>LG Smart TV</td>\n",
       "      <td>2021-05-22</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Peripheral compatibility</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Pending Customer Response</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Chat</td>\n",
       "      <td>2023-06-01 16:45:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Christopher Robbins</td>\n",
       "      <td>gonzalestracy@example.com</td>\n",
       "      <td>48</td>\n",
       "      <td>Other</td>\n",
       "      <td>Dell XPS</td>\n",
       "      <td>2020-07-14</td>\n",
       "      <td>Technical issue</td>\n",
       "      <td>Network problem</td>\n",
       "      <td>I'm facing a problem with my {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Case maybe show recently my computer follow.</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 11:14:38</td>\n",
       "      <td>2023-06-01 18:05:38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Christina Dillon</td>\n",
       "      <td>bradleyolson@example.org</td>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>Microsoft Office</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>Billing inquiry</td>\n",
       "      <td>Account access</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Try capital clearly never color toward story.</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social media</td>\n",
       "      <td>2023-06-01 07:29:40</td>\n",
       "      <td>2023-06-01 01:57:40</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alexander Carroll</td>\n",
       "      <td>bradleymark@example.com</td>\n",
       "      <td>67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Autodesk AutoCAD</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>Billing inquiry</td>\n",
       "      <td>Data loss</td>\n",
       "      <td>I'm having an issue with the {product_purchase...</td>\n",
       "      <td>Closed</td>\n",
       "      <td>West decision evidence bit.</td>\n",
       "      <td>Low</td>\n",
       "      <td>Email</td>\n",
       "      <td>2023-06-01 00:12:42</td>\n",
       "      <td>2023-06-01 19:53:42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticket ID        Customer Name              Customer Email  Customer Age  \\\n",
       "0          1        Marisa Obrien  carrollallison@example.com            32   \n",
       "1          2         Jessica Rios    clarkeashley@example.com            42   \n",
       "2          3  Christopher Robbins   gonzalestracy@example.com            48   \n",
       "3          4     Christina Dillon    bradleyolson@example.org            27   \n",
       "4          5    Alexander Carroll     bradleymark@example.com            67   \n",
       "\n",
       "  Customer Gender Product Purchased Date of Purchase      Ticket Type  \\\n",
       "0           Other        GoPro Hero       2021-03-22  Technical issue   \n",
       "1          Female       LG Smart TV       2021-05-22  Technical issue   \n",
       "2           Other          Dell XPS       2020-07-14  Technical issue   \n",
       "3          Female  Microsoft Office       2020-11-13  Billing inquiry   \n",
       "4          Female  Autodesk AutoCAD       2020-02-04  Billing inquiry   \n",
       "\n",
       "             Ticket Subject  \\\n",
       "0             Product setup   \n",
       "1  Peripheral compatibility   \n",
       "2           Network problem   \n",
       "3            Account access   \n",
       "4                 Data loss   \n",
       "\n",
       "                                  Ticket Description  \\\n",
       "0  I'm having an issue with the {product_purchase...   \n",
       "1  I'm having an issue with the {product_purchase...   \n",
       "2  I'm facing a problem with my {product_purchase...   \n",
       "3  I'm having an issue with the {product_purchase...   \n",
       "4  I'm having an issue with the {product_purchase...   \n",
       "\n",
       "               Ticket Status                                     Resolution  \\\n",
       "0  Pending Customer Response                                            NaN   \n",
       "1  Pending Customer Response                                            NaN   \n",
       "2                     Closed   Case maybe show recently my computer follow.   \n",
       "3                     Closed  Try capital clearly never color toward story.   \n",
       "4                     Closed                    West decision evidence bit.   \n",
       "\n",
       "  Ticket Priority Ticket Channel  First Response Time   Time to Resolution  \\\n",
       "0        Critical   Social media  2023-06-01 12:15:36                  NaN   \n",
       "1        Critical           Chat  2023-06-01 16:45:38                  NaN   \n",
       "2             Low   Social media  2023-06-01 11:14:38  2023-06-01 18:05:38   \n",
       "3             Low   Social media  2023-06-01 07:29:40  2023-06-01 01:57:40   \n",
       "4             Low          Email  2023-06-01 00:12:42  2023-06-01 19:53:42   \n",
       "\n",
       "   Customer Satisfaction Rating  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2                           3.0  \n",
       "3                           3.0  \n",
       "4                           1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line creates an instance of the OpenAI client, which is used to make API calls to services like ChatGPT, GPT-4, or DALL¬∑E.\n",
    "\n",
    "When OpenAI() is called without any parameters, it tries to read the API key from the environment variable OPENAI_API_KEY.\n",
    "\n",
    "**Note**- However, in the Skills Network environment, an OpenAI API key is not required, as the platform handles authentication internally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client (assumes OPENAI_API_KEY is set in env)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, We're defining a class called SupportResponse, and it inherits from BaseModel, which comes from Pydantic ‚Äî a Python library that helps validate and structure data.\n",
    "\n",
    "This class acts as a blueprint for what a valid AI-generated support response should look like. It makes sure that any response the AI gives follows specific rules.\n",
    "\n",
    "- The ```category``` field only accepts one of these values: ```\"billing\", \"technical\", \"account\", or \"other\".```\n",
    "   This helps classify the type of issue the customer is facing.\n",
    "- The ```priority``` field is limited to ```\"low\", \"medium\", or \"high\"``` indicating how urgent the issue is.\n",
    "- The ```escalate``` field is a boolean ‚Äî either ```True or False```. This shows whether the issue needs to be forwarded to a human or higher-level support.\n",
    "- The ```suggested_response``` is a string containing the ```actual message``` the AI should send back to the customer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "# SupportResponse using Pydantic V2\n",
    "\n",
    "class SupportResponse(BaseModel):\n",
    "    category: str = Field(..., description=\"The issue category\")\n",
    "    priority: str = Field(default=\"low\", description=\"Issue priority (low, medium, high)\")\n",
    "    escalate: bool = Field(..., description=\"Should this be escalated to a human?\")\n",
    "    suggested_response: str = Field(..., description=\"A helpful support reply\")\n",
    "\n",
    "    @field_validator(\"priority\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_priority(cls, v):\n",
    "        valid_priorities = {\"low\", \"medium\", \"high\"}\n",
    "        if isinstance(v, str) and v.lower() in valid_priorities:\n",
    "            return v.lower()\n",
    "        return \"low\"  # fallback if invalid\n",
    "\n",
    "    def priority_as_int(self) -> int:\n",
    "        priority_map = {\"low\": 1, \"medium\": 2, \"high\": 3}\n",
    "        return priority_map.get(self.priority, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we‚Äôll write a prompt that will be sent to the AI to guide its behavior during the conversation.\n",
    "\n",
    "This prompt works like an instruction ‚Äî it tells the AI how it should act. When using OpenAI‚Äôs chat models, we pass this as the very first message with the role set to \"system\". That way, the AI knows what kind of assistant it should be throughout the interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "User: I forgot my password and can‚Äôt login.\n",
    "Response:\n",
    "{\n",
    "  \"category\": \"Authentication\",\n",
    "  \"priority\": \"High\",\n",
    "  \"escalate\": true,\n",
    "  \"suggested_response\": \"You can reset your password from the login page. If that doesn‚Äôt work, we'll escalate this issue for manual support.\"\n",
    "}\n",
    "\n",
    "User: Please cancel my account.\n",
    "Response:\n",
    "{\n",
    "  \"category\": \"Subscription\",\n",
    "  \"priority\": \"Medium\",\n",
    "  \"escalate\": false,\n",
    "  \"suggested_response\": \"To cancel your subscription, go to Settings > Billing > Cancel Plan. Contact us if you need help.\"\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an Agent?\n",
    "\n",
    "An Agent is a special kind of setup that helps you manage how an AI (like GPT-4) interacts with users in a structured way.\n",
    "\n",
    "In PydanticAI, agents are defined using a class called Agent, which is built using Python‚Äôs @dataclass system. It allows you to:\n",
    "\n",
    "Set the type of input data or dependencies it needs (AgentDepsT)  \n",
    "Define the type of output you expect the agent to return (OutputDataT)  \n",
    "If you don‚Äôt customize these, the default setup looks like: Agent[None, str], meaning it doesn‚Äôt need extra input and returns a simple string.\n",
    "\n",
    "We use an instructions field to guide the AI‚Äôs behavior ‚Äî this is also known as the system prompt.\n",
    "\n",
    "For example, you might tell the model:\n",
    "\n",
    "‚ÄúAct like a support assistant. Return a JSON response with four specific fields.‚Äù\n",
    "You can also include few-shot examples, which are sample conversations (like {prompt}) that help the AI understand the format and tone you expect.  \n",
    "\n",
    "\n",
    "In this project, we‚Äôre using the GPT-4 model for better reasoning and output quality.\n",
    "You can read more about it here: https://openai.com/index/gpt-4/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent[SupportResponse](\n",
    "    instructions=f\"\"\"\n",
    "You are a helpful customer support assistant.\n",
    "You can use this CSV file: {df}\n",
    "\n",
    "Your task is to:\n",
    "- Match user input to any ticket using ticket_id, email, or customer_name.\n",
    "- Respond ONLY using the data in the CSV.\n",
    "- If no match is found, respond politely asking the user to check their input.\n",
    "- Output MUST be a valid JSON object in this exact format (no markdown, no prose):\n",
    "\n",
    "{{\n",
    "  \"category\": \"Connectivity\",\n",
    "  \"priority\": \"high\",\n",
    "  \"escalate\": true,\n",
    "  \"suggested_response\": \"Please update your Wi-Fi drivers and restart your router.\"\n",
    "}}\n",
    "\n",
    "Only return the JSON ‚Äî no extra text or explanation.\n",
    "\"\"\",\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    client=client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is nest_asyncio?\n",
    "nest_asyncio is a small Python library that lets you run asynchronous code (like async functions) multiple times in the same environment ‚Äî even if an event loop is already running.\n",
    "\n",
    "### Why do we need it?\n",
    "Jupyter notebooks already have their own event loop running in the background (to support things like live outputs and widgets).\n",
    "Normally, Python doesn‚Äôt allow you to start a new event loop when one is already active ‚Äî and that‚Äôs where nest_asyncio helps.\n",
    "\n",
    "It \"patches\" the existing loop so you can safely run async code inside your notebook without errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run_chatbot() function is an async loop that simulates a real-time conversation with an AI-powered customer support chatbot.\n",
    "\n",
    "Let's see how this function ```run_chatbot``` works step by step:\n",
    "\n",
    "It keeps asking the user for input (like a message or question).\n",
    "If the user types anything other than \"exit\", the input is sent to the AI agent using await agent.run(user_input).\n",
    "The AI's response is expected to follow a predefined format called SupportResponse ‚Äî which includes things like category, priority, escalation, and a suggested reply.\n",
    "The function checks if the AI actually returned something that matches this format.\n",
    "- If it does, the chatbot prints a clean, readable reply with all the details.\n",
    "-  If not, it shows a warning that the AI gave an unexpected output.\n",
    "The loop continues until the user types \"exit\", and any errors during the conversation are caught and displayed nicely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Customer Support Chatbot ‚Äî type 'exit' to quit\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  Christopher Robbins purchased a Dell XPS, If you need more details, please let me know.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Technical issue\n",
      "Priority        : low\n",
      "Escalate        : No\n",
      "Suggested Reply : I'm here to assist with the Dell XPS purchased by Christopher Robbins. Please let me know your specific concern or issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  My Dell XPS keeps dorpping from Wi-Fi every few minutes, which is really frustrating. I'd appreciate some help troubleshooting this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Connectivity\n",
      "Priority        : high\n",
      "Escalate        : Yes\n",
      "Suggested Reply : Please update your Wi-Fi drivers and restart your router.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  My MacBook Pro has no Spanish keyboard layout, Can you help me - I want to print in Spanish?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Product inquiry\n",
      "Priority        : medium\n",
      "Escalate        : No\n",
      "Suggested Reply : Please check your device's language and keyboard settings, or consult the user manual for instructions on configuring the Spanish keyboard layout.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  –ß—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –≤ —Ä–æ–∑–µ—Ç–∫–µ –Ω–µ—Ç —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–∞? –Ø —Ö–æ—á—É –≤—Å–∫–∏–ø—è—Ç–∏—Ç—å —á–∞–π–Ω–∏–∫\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Hardware issue\n",
      "Priority        : high\n",
      "Escalate        : Yes\n",
      "Suggested Reply : Please check your electrical outlet and circuit breaker to ensure there's power supply. If the issue persists, contact a qualified electrician.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  –ß—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –≤ —Ä–æ–∑–µ—Ç–∫–µ –Ω–µ—Ç —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–∞? –Ø —Ö–æ—á—É –≤—Å–∫–∏–ø—è—Ç–∏—Ç—å —á–∞–π–Ω–∏–∫. –î–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Hardware issue\n",
      "Priority        : high\n",
      "Escalate        : Yes\n",
      "Suggested Reply : –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —ç–ª–µ–∫—Ç—Ä–æ—Å–Ω–∞–±–∂–µ–Ω–∏–µ –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ä–æ–∑–µ—Ç–∫–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —ç–ª–µ–∫—Ç—Ä–∏–∫—É.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  –ß—Ç–æ –º–Ω–µ –¥–µ–ª–∞—Ç—å –µ—Å–ª–∏ –≤ —Ä–æ–∑–µ—Ç–∫–µ –Ω–µ—Ç —ç–ª–µ–∫—Ç—Ä–∏—á–µ—Å—Ç–≤–∞? –Ø —Ö–æ—á—É –≤—Å–∫–∏–ø—è—Ç–∏—Ç—å —á–∞–π–Ω–∏–∫. –î–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –Ω–µ–º–µ—Ü–∫–æ–º.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI Response:\n",
      "Category        : Electrical Issue\n",
      "Priority        : high\n",
      "Escalate        : Yes\n",
      "Suggested Reply : Bitte √ºberpr√ºfen Sie die Sicherung oder den Stromanschluss in Ihrer Steckdose. Wenn das Problem weiterhin besteht, kontaktieren Sie einen Elektriker.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üßë You:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Exiting chatbot.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "async def run_chatbot():\n",
    "    print(\" Customer Support Chatbot ‚Äî type 'exit' to quit\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"üßë You: \").strip()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\" Exiting chatbot.\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            result = await agent.run(user_input)\n",
    "            output = result.output\n",
    "\n",
    "            # Try parsing the result into SupportResponse\n",
    "            if isinstance(output, SupportResponse):\n",
    "                response = output\n",
    "            elif isinstance(output, dict):\n",
    "                response = SupportResponse(**output)\n",
    "            elif isinstance(output, str):\n",
    "                response = SupportResponse(**json.loads(output))\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported output format from agent.\")\n",
    "\n",
    "            # ‚úÖ Print structured response\n",
    "            print(\"\\nAI Response:\")\n",
    "            print(f\"Category        : {response.category}\")\n",
    "            print(f\"Priority        : {response.priority}\")\n",
    "            print(f\"Escalate        : {'Yes' if response.escalate else 'No'}\")\n",
    "            print(f\"Suggested Reply : {response.suggested_response}\\n\")\n",
    "\n",
    "        except (ValidationError, ValueError, json.JSONDecodeError) as e:\n",
    "            print(\"\\n‚ùå Could not parse structured output from agent:\")\n",
    "            print(output)\n",
    "\n",
    "# Run this to launch chatbot\n",
    "await run_chatbot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Input Questions for above propmt\n",
    "#### Q1: Christopher Robbins purchased a Dell XPS. If you need more details, please let us know.\n",
    "#### Q2: My Dell XPS keeps dropping from Wi-Fi every few minutes, which is really frustrating. I‚Äôd appreciate some help troubleshooting this issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Design a mood-based AI assistant that suggests recipes personalized to both the user's emotional state and their dietary preferences using pydantic_ai's Agent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dish_name='–†–∞–≥—É –∏–∑ –≥–æ–≤—è–¥–∏–Ω—ã —Å –æ–≤–æ—â–∞–º–∏' description='–≠—Ç–æ —Å—ã—Ç–Ω–æ–µ –∏ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ–µ –±–ª—é–¥–æ –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ–π–¥–µ—Ç –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ –≤–µ—Å—å –¥–µ–Ω—å –µ–ª –º—è—Å–æ –∏ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –≤ –ø–∏—Ç–∞–Ω–∏–∏. –†–∞–≥—É –∏–∑ –≥–æ–≤—è–¥–∏–Ω—ã —Å –æ–≤–æ—â–∞–º–∏ –Ω–∞–ø–æ–ª–Ω—è–µ—Ç —ç–Ω–µ—Ä–≥–∏–µ–π –∏ –Ω–∞—Å—ã—â–∞–µ—Ç, —Å–æ–∑–¥–∞–≤–∞—è –æ—â—É—â–µ–Ω–∏–µ —É—é—Ç–∞ –∏ –∫–æ–º—Ñ–æ—Ä—Ç–∞.' ingredients=['1 –∫–≥ –≥–æ–≤—è–¥–∏–Ω—ã', '2 –º–æ—Ä–∫–æ–≤–∏', '2 –∫–∞—Ä—Ç–æ—à–∫–∏', '1 –ª—É–∫', '3 –∑—É–±—á–∏–∫–∞ —á–µ—Å–Ω–æ–∫–∞', '400 –≥ —Ç–æ–º–∞—Ç–æ–≤ –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º —Å–æ–∫—É', '500 –º–ª –≥–æ–≤—è–∂—å–µ–≥–æ –±—É–ª—å–æ–Ω–∞', '2 —Å—Ç. –ª–æ–∂–∫–∏ —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º–∞—Å–ª–∞', '—Å–æ–ª—å', '–ø–µ—Ä–µ—Ü', '–ª–∞–≤—Ä–æ–≤—ã–π –ª–∏—Å—Ç'] cooking_time_minutes=120\n",
      "---------------------\n",
      "MoodDeps(user_id=3, mood='–∂—Ä—É –º—è—Å–æ —Ü–µ–ª—ã–π –¥–µ–Ω—å', db=<__main__.UserProfile object at 0x78886c5ecf20>)\n",
      "---------------------\n",
      "AgentRunResult(output=RecipeSuggestion(dish_name='–†–∞–≥—É –∏–∑ –≥–æ–≤—è–¥–∏–Ω—ã —Å –æ–≤–æ—â–∞–º–∏', description='–≠—Ç–æ —Å—ã—Ç–Ω–æ–µ –∏ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ–µ –±–ª—é–¥–æ –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥–æ–π–¥–µ—Ç –¥–ª—è —Ç–µ—Ö, –∫—Ç–æ –≤–µ—Å—å –¥–µ–Ω—å –µ–ª –º—è—Å–æ –∏ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –≤ –ø–∏—Ç–∞–Ω–∏–∏. –†–∞–≥—É –∏–∑ –≥–æ–≤—è–¥–∏–Ω—ã —Å –æ–≤–æ—â–∞–º–∏ –Ω–∞–ø–æ–ª–Ω—è–µ—Ç —ç–Ω–µ—Ä–≥–∏–µ–π –∏ –Ω–∞—Å—ã—â–∞–µ—Ç, —Å–æ–∑–¥–∞–≤–∞—è –æ—â—É—â–µ–Ω–∏–µ —É—é—Ç–∞ –∏ –∫–æ–º—Ñ–æ—Ä—Ç–∞.', ingredients=['1 –∫–≥ –≥–æ–≤—è–¥–∏–Ω—ã', '2 –º–æ—Ä–∫–æ–≤–∏', '2 –∫–∞—Ä—Ç–æ—à–∫–∏', '1 –ª—É–∫', '3 –∑—É–±—á–∏–∫–∞ —á–µ—Å–Ω–æ–∫–∞', '400 –≥ —Ç–æ–º–∞—Ç–æ–≤ –≤ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–º —Å–æ–∫—É', '500 –º–ª –≥–æ–≤—è–∂—å–µ–≥–æ –±—É–ª—å–æ–Ω–∞', '2 —Å—Ç. –ª–æ–∂–∫–∏ —Ä–∞—Å—Ç–∏—Ç–µ–ª—å–Ω–æ–≥–æ –º–∞—Å–ª–∞', '—Å–æ–ª—å', '–ø–µ—Ä–µ—Ü', '–ª–∞–≤—Ä–æ–≤—ã–π –ª–∏—Å—Ç'], cooking_time_minutes=120))\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Simulated database for user preferences\n",
    "class UserProfile:\n",
    "    @classmethod\n",
    "    async def get_diet_type(cls, id: int) -> str:\n",
    "        return \"vegetarian\" if id == 7 else \"no restrictions\"\n",
    "\n",
    "\n",
    "# Define dependencies passed to the agent\n",
    "@dataclass\n",
    "class MoodDeps:\n",
    "    user_id: int\n",
    "    mood: str  # e.g. 'happy', 'sad', 'tired'\n",
    "    db: UserProfile\n",
    "\n",
    "\n",
    "# Define the expected structured output\n",
    "class RecipeSuggestion(BaseModel):\n",
    "    dish_name: str\n",
    "    description: str\n",
    "    ingredients: list[str]\n",
    "    cooking_time_minutes: int\n",
    "\n",
    "\n",
    "# Create the agent with schema guidance\n",
    "mood_chef_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=MoodDeps,\n",
    "    result_type=RecipeSuggestion,\n",
    "    system_prompt=(\n",
    "        \"You are EmoChef ‚Äì a thoughtful and mood-sensitive recipe assistant. \"\n",
    "        \"Based on the user's mood and diet type, suggest a comforting or energizing recipe.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Inject additional context using system_prompt decorator\n",
    "@mood_chef_agent.system_prompt\n",
    "async def add_diet_info(ctx: RunContext[MoodDeps]) -> str:\n",
    "    diet = await ctx.deps.db.get_diet_type(ctx.deps.user_id)\n",
    "    return f\"The user is feeling {ctx.deps.mood} and follows a {diet} diet.\"\n",
    "\n",
    "\n",
    "# Run the agent using await (for Jupyter / Colab environments)\n",
    "async def main():\n",
    "    deps = MoodDeps(user_id=3, mood=\"–∂—Ä—É –º—è—Å–æ —Ü–µ–ª—ã–π –¥–µ–Ω—å\", db=UserProfile())\n",
    "    result = await mood_chef_agent.run(\"What should I cook tonight? Give an answer in russian.\", deps=deps)\n",
    "    print(result.output)\n",
    "    print('---------------------')\n",
    "    print(deps)\n",
    "    print('---------------------')\n",
    "    print(result)\n",
    "\n",
    "\n",
    "# Await the main function\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Simulated database for user preferences\n",
    "class UserProfile:\n",
    "    @classmethod\n",
    "    async def get_diet_type(cls, id: int) -> str:\n",
    "        return \"vegetarian\" if id == 7 else \"no restrictions\"\n",
    "\n",
    "\n",
    "# Define dependencies passed to the agent\n",
    "@dataclass\n",
    "class MoodDeps:\n",
    "    user_id: int\n",
    "    mood: str  # e.g. 'happy', 'sad', 'tired'\n",
    "    db: UserProfile\n",
    "\n",
    "\n",
    "# Define the expected structured output\n",
    "class RecipeSuggestion(BaseModel):\n",
    "    dish_name: str\n",
    "    description: str\n",
    "    ingredients: list[str]\n",
    "    cooking_time_minutes: int\n",
    "\n",
    "\n",
    "# Create the agent with schema guidance\n",
    "mood_chef_agent = Agent(\n",
    "    \"openai:gpt-4o\",\n",
    "    deps_type=MoodDeps,\n",
    "    result_type=RecipeSuggestion,\n",
    "    system_prompt=(\n",
    "        \"You are EmoChef ‚Äì a thoughtful and mood-sensitive recipe assistant. \"\n",
    "        \"Based on the user's mood and diet type, suggest a comforting or energizing recipe.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Inject additional context using system_prompt decorator\n",
    "@mood_chef_agent.system_prompt\n",
    "async def add_diet_info(ctx: RunContext[MoodDeps]) -> str:\n",
    "    diet = await ctx.deps.db.get_diet_type(ctx.deps.user_id)\n",
    "    return f\"The user is feeling {ctx.deps.mood} and follows a {diet} diet.\"\n",
    "\n",
    "\n",
    "# Run the agent using await (for Jupyter / Colab environments)\n",
    "async def main():\n",
    "    deps = MoodDeps(user_id=7, mood=\"tired\", db=UserProfile())\n",
    "    result = await mood_chef_agent.run(\"What should I cook tonight?\", deps=deps)\n",
    "    print(result.data)\n",
    "\n",
    "\n",
    "# Await the main function\n",
    "await main()\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jigisha Barbhaya](https://www.linkedin.com/in/jigisha-barbhaya/)\n",
    "> <i> As a data scientist in IBM, I have always been passionate about sharing my knowledge and helping others learn about the field. I believe that everyone should have the opportunity to learn about data science, regardless of their background or experience level. This belief has inspired me to become a learning content provider, creating and sharing educational materials that are accessible and engaging for everyone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Faranak Heidari](https://www.linkedin.com/in/faranakhdr/)  \n",
    "> <i> a datascientist and GenAI developer in IBM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Karan Goswami](https://www.linkedin.com/in/karan-25au2000/) is a dedicated Data Scientist and an AI enthusiast, currently working at IBM's SkillsBuild Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright ¬© 2025 IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "6aacae1c20bd424db7bcb3a154bc922824f2eda20732fdaa7f790b901f635764"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
